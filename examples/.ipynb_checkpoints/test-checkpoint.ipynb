{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys \n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "sys.path.append(\"..\")\n",
    "from data_process import config_amazon_books, config_taobao, config_customize\n",
    "from data_process.get_standard_input import get_standard_input\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import chain\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from deepctr.layers import combined_dnn_input, concat_func, add_func, FM, DNN_UDG, rig, rmse, CustomCallback\n",
    "from deepctr.models import DeepFM, DeepFM_UDG, PNN, PNN_UDG, WDL, WDL_UDG, DIEN, DIN, DIEN_UDG, DIN, DIN_UDG\n",
    "from deepctr.inputs import create_embedding_dict, embedding_lookup, mergeDict\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, VarLenSparseFeat, get_feature_names, build_input_features, get_linear_logit,input_from_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-08-14 02:39:56'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time  # 引入time模块\n",
    "ticks = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()) \n",
    "ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_names = ['userId', 'itemId', 'category', 'final_gender_code', 'age_level']\n",
    "#config = config_taobao\n",
    "train = pd.read_csv('../dataset/amazon/a_test.csv')\n",
    "test = pd.read_csv('../dataset/amazon/b_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(train, max_len, signal, dataset):\n",
    "    if dataset == 'alimama':\n",
    "        input_dict = {'userId': [], 'final_gender_code': [], 'itemId': [], \n",
    "                    'category': [], 'age_level':[],\n",
    "                    'hist_itemId': [], 'hist_category': [],\n",
    "                    'neg_hist_itemId': [], 'neg_hist_category': [],\n",
    "                    \"seq_length\": []}\n",
    "        train_hist_item_list = []\n",
    "        train_hist_cate_list = []\n",
    "        train_neg_hist_item_list = []\n",
    "        train_neg_hist_cate_list = []\n",
    "        input_dict['userId'] = train['userId'].values\n",
    "        input_dict['final_gender_code'] = train['final_gender_code'].values\n",
    "        input_dict['category'] = train['category'].values\n",
    "        input_dict['age_level'] = train['age_level'].values\n",
    "        input_dict['itemId'] = train['itemId'].values\n",
    "        train_label = train['rating'].values\n",
    "        for x in tqdm(range(len(train))):       \n",
    "            train_hist_item_list.append(list(map(int, eval(train['hist_item_list'][x]))))\n",
    "            train_hist_cate_list.append(list(map(int, eval(train['hist_cate_list'][x]))))\n",
    "            train_neg_hist_item_list.append(list(map(int, eval(train['neg_hist_item_list'][x]))))\n",
    "            train_neg_hist_cate_list.append(list(map(int, eval(train['neg_hist_item_list'][x]))))\n",
    "        all_len = list(map(len, train_hist_item_list))\n",
    "        if signal == 'test':\n",
    "            train_hist_item_list = pad_sequences(train_hist_item_list, maxlen=max(all_len), padding='post', )\n",
    "            train_hist_cate_list = pad_sequences(train_hist_cate_list, maxlen=max(all_len), padding='post', )\n",
    "            train_neg_hist_item_list = pad_sequences(train_neg_hist_item_list, maxlen=max(all_len), padding='post', )\n",
    "            train_neg_hist_cate_list = pad_sequences(train_neg_hist_cate_list, maxlen=max(all_len), padding='post', )\n",
    "        else:\n",
    "            train_hist_item_list = pad_sequences(train_hist_item_list, maxlen=max_len, padding='post', )\n",
    "            train_hist_cate_list = pad_sequences(train_hist_cate_list, maxlen=max_len, padding='post', )\n",
    "            train_neg_hist_item_list = pad_sequences(train_neg_hist_item_list, maxlen=max_len, padding='post', )\n",
    "            train_neg_hist_cate_list = pad_sequences(train_neg_hist_cate_list, maxlen=max_len, padding='post', )\n",
    "        input_dict['hist_itemId'] = train_hist_item_list\n",
    "        input_dict['hist_category'] = train_hist_cate_list\n",
    "        input_dict['neg_hist_itemId'] = train_neg_hist_item_list\n",
    "        input_dict['neg_hist_category'] = train_neg_hist_cate_list\n",
    "        input_dict['seq_length'] = np.array(all_len)\n",
    "\n",
    "    return input_dict, train_label, max(all_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>itemId</th>\n",
       "      <th>rating</th>\n",
       "      <th>final_gender_code</th>\n",
       "      <th>age_level</th>\n",
       "      <th>category</th>\n",
       "      <th>hist_item_list</th>\n",
       "      <th>hist_cate_list</th>\n",
       "      <th>neg_hist_item_list</th>\n",
       "      <th>neg_hist_cate_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>17993</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1400457600</td>\n",
       "      <td>31023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1379548800</td>\n",
       "      <td>58134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1379548800</td>\n",
       "      <td>18820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1379548800</td>\n",
       "      <td>62555</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>['58134']</td>\n",
       "      <td>['611']</td>\n",
       "      <td>['48992']</td>\n",
       "      <td>['629']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>11</td>\n",
       "      <td>1362096000</td>\n",
       "      <td>29788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>['1311']</td>\n",
       "      <td>['573']</td>\n",
       "      <td>['28235']</td>\n",
       "      <td>['388']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>11</td>\n",
       "      <td>1362096000</td>\n",
       "      <td>32494</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>['1311', '30401']</td>\n",
       "      <td>['573', '573']</td>\n",
       "      <td>['28235', '24433']</td>\n",
       "      <td>['388', '703']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>11</td>\n",
       "      <td>1362096000</td>\n",
       "      <td>18081</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>['1311', '30401']</td>\n",
       "      <td>['573', '573']</td>\n",
       "      <td>['28235', '24433']</td>\n",
       "      <td>['388', '703']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>1362700800</td>\n",
       "      <td>53400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>['1311', '30401', '32494']</td>\n",
       "      <td>['573', '573', '321']</td>\n",
       "      <td>['28235', '24433', '12278']</td>\n",
       "      <td>['388', '703', '1']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>1362700800</td>\n",
       "      <td>24182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>['1311', '30401', '32494']</td>\n",
       "      <td>['573', '573', '321']</td>\n",
       "      <td>['28235', '24433', '12278']</td>\n",
       "      <td>['388', '703', '1']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  userId   timestamp  itemId  rating  final_gender_code  \\\n",
       "0            0       0  1400457600   17993       1                  0   \n",
       "1            1       0  1400457600   31023       0                  0   \n",
       "2            2       1  1379548800   58134       1                  0   \n",
       "3            3       1  1379548800   18820       0                  0   \n",
       "4            4       1  1379548800   62555       1                  0   \n",
       "..         ...     ...         ...     ...     ...                ...   \n",
       "95          95      11  1362096000   29788       0                  0   \n",
       "96          96      11  1362096000   32494       1                  0   \n",
       "97          97      11  1362096000   18081       0                  0   \n",
       "98          98      11  1362700800   53400       1                  0   \n",
       "99          99      11  1362700800   24182       0                  0   \n",
       "\n",
       "    age_level  category              hist_item_list         hist_cate_list  \\\n",
       "0           0     513.0                          []                     []   \n",
       "1           0     351.0                          []                     []   \n",
       "2           0     611.0                          []                     []   \n",
       "3           0     744.0                          []                     []   \n",
       "4           0     578.0                   ['58134']                ['611']   \n",
       "..        ...       ...                         ...                    ...   \n",
       "95          0     504.0                    ['1311']                ['573']   \n",
       "96          0     321.0           ['1311', '30401']         ['573', '573']   \n",
       "97          0     241.0           ['1311', '30401']         ['573', '573']   \n",
       "98          0     351.0  ['1311', '30401', '32494']  ['573', '573', '321']   \n",
       "99          0     558.0  ['1311', '30401', '32494']  ['573', '573', '321']   \n",
       "\n",
       "             neg_hist_item_list   neg_hist_cate_list  \n",
       "0                            []                   []  \n",
       "1                            []                   []  \n",
       "2                            []                   []  \n",
       "3                            []                   []  \n",
       "4                     ['48992']              ['629']  \n",
       "..                          ...                  ...  \n",
       "95                    ['28235']              ['388']  \n",
       "96           ['28235', '24433']       ['388', '703']  \n",
       "97           ['28235', '24433']       ['388', '703']  \n",
       "98  ['28235', '24433', '12278']  ['388', '703', '1']  \n",
       "99  ['28235', '24433', '12278']  ['388', '703', '1']  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb187d8085b240a591d4b155d9d01711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c475b2c9a54d58895732888337f924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model_input, test_label, max_len = get_input(test, 0, 'test', 'alimama')\n",
    "train_model_input, train_label, _ = get_input(train, max_len, 'train', 'alimama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 02:40:53.940960 139898295519040 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, train[feat].nunique() + 1, embedding_dim=128) for feat in fixlen_feature_names]\n",
    "#fixlen_feature_columns += [DenseFeat(feat, 1,) for feat in config.dense_features]\n",
    "fixlen_feature_columns += [\n",
    "    VarLenSparseFeat(SparseFeat('hist_itemId', train['itemId'].nunique() + 1,\n",
    "                     embedding_dim = 128, embedding_name='itemId'), maxlen=max_len, \n",
    "                    length_name='seq_length'),\n",
    "    VarLenSparseFeat(SparseFeat('hist_category', train['category'].nunique() + 1,\n",
    "                     embedding_dim = 128, embedding_name='category'), maxlen=max_len, \n",
    "                    length_name='seq_length'),\n",
    "    VarLenSparseFeat(SparseFeat('neg_hist_itemId', train['itemId'].nunique() + 1,\n",
    "                     embedding_dim = 128, embedding_name='itemId'), maxlen=max_len, \n",
    "                    length_name='seq_length'),\n",
    "    VarLenSparseFeat(SparseFeat('neg_hist_category', train['category'].nunique() + 1,\n",
    "                     embedding_dim = 128, embedding_name='category'), maxlen=max_len, \n",
    "                    length_name='seq_length')\n",
    "]\n",
    "behavior_feature_list = ['itemId', 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "untrain_embedding_dict: []\n",
      "uid_emb_list: [<tf.Tensor 'udg__emb_userId_1/embedding_lookup/Identity_1:0' shape=(?, 1, 128) dtype=float32>]\n",
      "Tensor(\"concatenate_11/concat:0\", shape=(?, 11, 256), dtype=float32)\n",
      "Tensor(\"concatenate_14/concat:0\", shape=(?, 11, 256), dtype=float32)\n",
      "Tensor(\"flatten_6/Reshape:0\", shape=(?, 896), dtype=float32) Tensor(\"flatten_7/Reshape:0\", shape=(?, 128), dtype=float32)\n",
      "?: Tensor(\"concatenate_16/concat:0\", shape=(?, 1024), dtype=float32)\n",
      "1024 128\n",
      "[[128, 896, 896], [128, 200, 200], [128, 80, 80]]\n"
     ]
    }
   ],
   "source": [
    "# untrainable_features = ['category', 'final_gender_code', 'age_level']\n",
    "# untrainable_features_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=128, \n",
    "#                                            trainable=False) for feat in untrainable_features]\n",
    "untrainable_features_columns = []\n",
    "# model = DIEN(fixlen_feature_columns, behavior_feature_list, \n",
    "#              dnn_hidden_units=[200, 80], dnn_dropout=0, gru_type=\"AUGRU\", use_negsampling=True)\n",
    "model = DIEN_UDG(fixlen_feature_columns, untrainable_features_columns, \n",
    "                 behavior_feature_list, dnn_hidden_units=[200, 80], \n",
    "                 dnn_dropout=0, gru_type=\"AUGRU\", use_negsampling=True, \n",
    "                 uid_feature_name='userId', udg_embedding_size=128)\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100/100 [==============================] - 2s 16ms/sample - loss: 0.8395 - binary_crossentropy: 0.6931\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_label, verbose=1, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def rig(y_true, y_pred):\n",
    "    p_hat = np.average(y_true)\n",
    "    h = - p_hat * np.log(p_hat) - (1-p_hat) * np.log(1-p_hat)\n",
    "    ce = 0.\n",
    "    for i in range(len(y_true)):\n",
    "        if y_pred[i] == 0:\n",
    "            y_pred[i] = 0.00000001\n",
    "        elif y_pred[i] == 1:\n",
    "            y_pred[i] = 1 - 0.00000001\n",
    "        ce += y_true[i] * np.log(y_pred[i]) + (1-y_true[i]) * np.log(1-y_pred[i])\n",
    "    ce = ce / len(y_true)\n",
    "    rig = (h + ce) / h\n",
    "    return rig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../dataset/ml-20m/train.txt')\n",
    "test = pd.read_csv('../dataset/ml-20m/test.txt')\n",
    "sparse_features = [\"movieId\", \"userId\", \"genres\"]\n",
    "dense_features = []\n",
    "untrainable_features = []\n",
    "untrainable_features_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 00:37:19.899135 140007159899968 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../dataset/alimama/train_small.txt')\n",
    "test = pd.read_csv('../dataset/alimama/test_small.txt')\n",
    "sparse_features = [\"itemId\", \"userId\", \"category\", 'final_gender_code', 'age_level']\n",
    "#dense_features = ['price']\n",
    "dense_features = []\n",
    "untrainable_features = ['category', 'final_gender_code', 'age_level']\n",
    "untrainable_features_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=emb, \n",
    "                                           trainable=False) for feat in untrainable_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('../dataset/alimama/train.txt')\n",
    "#test = pd.read_csv('../dataset/alimama/test.txt')\n",
    "sparse_features = [\"itemId\", \"userId\", \"category\", 'brand', 'final_gender_code', 'age_level', 'occupation']\n",
    "#sparse_features = [\"itemId\", \"userId\", \"category\"]\n",
    "dense_features = ['price']\n",
    "#dense_features = []\n",
    "trainable_features = ['userId']\n",
    "untrainable_features = ['brand', 'final_gender_code', 'age_level', 'occupation']\n",
    "target = ['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=emb) for feat in sparse_features] + [DenseFeat(feat, 1,) for feat in dense_features]\n",
    "linear_feature_columns = fixlen_feature_columns \n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "untrainable_features_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=emb, trainable=False) for feat in untrainable_features]\n",
    "#trainable_features_columns = [SparseFeat(feat, train[feat].nunique(), embedding_dim=128, trainable=False) for feat in trainable_features]\n",
    "#feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "train_model_input = {name: train[name] for name in sparse_features+dense_features}  #\n",
    "test_model_input = {name: test[name] for name in sparse_features+dense_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0811 00:37:31.672695 140007159899968 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:253: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0811 00:37:31.895622 140007159899968 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2304)\n",
      "[[1024, 1280, 1280], [1024, 200, 200], [1024, 80, 80]]\n",
      "(?, 1280)\n"
     ]
    }
   ],
   "source": [
    "model = DeepFM_UDG(linear_feature_columns, dnn_feature_columns, untrainable_features_columns, \n",
    "                       (200, 80), uid_feature_name='userId', udg_embedding_size=emb)\n",
    "model1 = DeepFM(linear_feature_columns, dnn_feature_columns, [], (200, 80))\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'], )\n",
    "model1.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0810 15:59:50.214119 139771793971008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:253: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0810 15:59:50.261312 139771793971008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"flatten/Reshape:0\", shape=(?, 768), dtype=float32)\n",
      "Tensor(\"concatenate_4/concat:0\", shape=(?, 1024), dtype=float32)\n",
      "[[256, 768, 768], [256, 200, 200], [256, 80, 80]]\n"
     ]
    }
   ],
   "source": [
    "model = WDL(linear_feature_columns, dnn_feature_columns, [], (200, 80))\n",
    "model1 = WDL_UDG(linear_feature_columns, dnn_feature_columns, untrainable_features_columns, (200, 80), uid_feature_name='userId', udg_embedding_size=emb)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'], )\n",
    "model1.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f564a04a9893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model = WDL_UDG(dnn_feature_columns, untrainable_features_columns, (200, 80), uid_feature_name='userId', \n\u001b[0;32m----> 2\u001b[0;31m                     udg_embedding_size=emb)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWDL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muntrainable_features_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuanzhiyu/.jupyter/DeepCTR-master/deepctr/models/wdl_udg.py\u001b[0m in \u001b[0;36mWDL_UDG\u001b[0;34m(linear_feature_columns, dnn_feature_columns, untrain_feature_columns, dnn_hidden_units, l2_reg_linear, l2_reg_embedding, l2_reg_dnn, seed, dnn_dropout, dnn_activation, task, uid_feature_name, udg_embedding_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m     linear_logit = get_linear_logit(features, linear_feature_columns, untrain_feature_columns, \n\u001b[1;32m     50\u001b[0m                                     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                                     l2_reg=l2_reg_linear)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     sparse_embedding_list, dense_value_list, untrain_embedding_list = input_from_feature_columns(features, dnn_feature_columns, \n",
      "\u001b[0;32m/home/yuanzhiyu/.jupyter/DeepCTR-master/deepctr/feature_column.py\u001b[0m in \u001b[0;36mget_linear_logit\u001b[0;34m(features, feature_columns, untrain_feature_columns, units, use_bias, seed, prefix, l2_reg)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 sparsefeat=linear_feature_columns[i].sparsefeat._replace(embedding_dim=1))\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mlinear_emb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_from_feature_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muntrain_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     _, dense_input_list,_ = input_from_feature_columns(features, linear_feature_columns, untrain_feature_columns, \n\u001b[1;32m    150\u001b[0m                                                      l2_reg, seed, prefix=prefix)\n",
      "\u001b[0;32m/home/yuanzhiyu/.jupyter/DeepCTR-master/deepctr/feature_column.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 sparsefeat=linear_feature_columns[i].sparsefeat._replace(embedding_dim=1))\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mlinear_emb_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_from_feature_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muntrain_feature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     _, dense_input_list,_ = input_from_feature_columns(features, linear_feature_columns, untrain_feature_columns, \n\u001b[1;32m    150\u001b[0m                                                      l2_reg, seed, prefix=prefix)\n",
      "\u001b[0;32m/home/yuanzhiyu/.jupyter/DeepCTR-master/deepctr/feature_column.py\u001b[0m in \u001b[0;36minput_from_feature_columns\u001b[0;34m(features, feature_columns, untrain_feature_columns, l2_reg, seed, prefix, seq_mask_zero, support_dense, support_group)\u001b[0m\n\u001b[1;32m    184\u001b[0m                                                     seq_mask_zero=seq_mask_zero)\n\u001b[1;32m    185\u001b[0m     group_sparse_embedding_dict, untrain_embedding_dict = embedding_lookup(embedding_matrix_dict, features,\n\u001b[0;32m--> 186\u001b[0;31m                                                                            sparse_feature_columns, untrain_feature_columns)\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0mdense_value_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dense_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupport_dense\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_value_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yuanzhiyu/.jupyter/DeepCTR-master/deepctr/inputs.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[0;34m(sparse_embedding_dict, sparse_input_dict, sparse_feature_columns, untrain_feature_columns, return_feat_list, mask_feat_list, to_list)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mgroup_embedding_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muntrain_feature_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mfeature_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0membedding_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_feat_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturn_feat_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "model = PNN_UDG(dnn_feature_columns, untrainable_features_columns, (200, 80), uid_feature_name='userId', \n",
    "                    udg_embedding_size=emb)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'], )\n",
    "model1 = PNN(dnn_feature_columns, untrainable_features_columns, (200, 80))\n",
    "model1.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'], )\n",
    "init_lr = float(tf.keras.backend.get_value(model.optimizer.learning_rate))\n",
    "lr = [init_lr, init_lr/2, init_lr/4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "itemId (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "userId (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "final_gender_code (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age_level (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_itemId (Embedding)   (None, 1, 256)       77611008    itemId[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_userId (Embedding)   (None, 1, 256)       96640768    userId[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_category (Embedding) (None, 1, 256)       1352704     category[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_final_gender_code (E (None, 1, 256)       512         final_gender_code[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_age_level (Embedding (None, 1, 256)       1792        age_level[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_itemId (Embed (None, 1, 1)         303168      itemId[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_userId (Embed (None, 1, 1)         377503      userId[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_category (Emb (None, 1, 1)         5284        category[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_final_gender_ (None, 1, 1)         2           final_gender_code[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_age_level (Em (None, 1, 1)         7           age_level[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_7 (NoMask)              (None, 1, 256)       0           sparse_emb_itemId[0][0]          \n",
      "                                                                 sparse_emb_userId[0][0]          \n",
      "                                                                 sparse_emb_category[0][0]        \n",
      "                                                                 sparse_emb_final_gender_code[0][0\n",
      "                                                                 sparse_emb_age_level[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_5 (NoMask)              (None, 1, 1)         0           linear0sparse_emb_itemId[0][0]   \n",
      "                                                                 linear0sparse_emb_userId[0][0]   \n",
      "                                                                 linear0sparse_emb_category[0][0] \n",
      "                                                                 linear0sparse_emb_final_gender_co\n",
      "                                                                 linear0sparse_emb_age_level[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1, 1280)      0           no_mask_7[0][0]                  \n",
      "                                                                 no_mask_7[1][0]                  \n",
      "                                                                 no_mask_7[2][0]                  \n",
      "                                                                 no_mask_7[3][0]                  \n",
      "                                                                 no_mask_7[4][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 5)         0           no_mask_5[0][0]                  \n",
      "                                                                 no_mask_5[1][0]                  \n",
      "                                                                 no_mask_5[2][0]                  \n",
      "                                                                 no_mask_5[3][0]                  \n",
      "                                                                 no_mask_5[4][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1280)         0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "linear_1 (Linear)               (None, 1, 1)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dnn (DNN)                       (None, 128)          180480      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "no_mask_6 (NoMask)              (None, 1, 1)         0           linear_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (1, 1)               0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            128         dnn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1, 1)         0           no_mask_6[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prediction_layer_1 (PredictionL (None, 1)            1           add_4[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 176,473,357\n",
      "Trainable params: 176,473,357\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./trained_data/model/PNN/alimama/1_0.645_nan_0.4835_0.0467.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = pred_ans.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6617"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(log_loss(test[target].values, pred_ans), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5210\u001b[0;31m                     \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5211\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ead687f1d3b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5218\u001b[0m                         \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5219\u001b[0m                     )\n\u001b[0;32m-> 5220\u001b[0;31m                 \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dir_additions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "test[target].values = test[target].values.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451087</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451088</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451089</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451090</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451091</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451092 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating\n",
       "0            1\n",
       "1            0\n",
       "2            1\n",
       "3            0\n",
       "4            1\n",
       "...        ...\n",
       "451087       0\n",
       "451088       1\n",
       "451089       1\n",
       "451090       1\n",
       "451091       0\n",
       "\n",
       "[451092 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f056bf3e400>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAclElEQVR4nO3daZAc533f8e9/eo7d2Xuxi4NYiABFkCIlyqS0og7aiiyXKJhxRLmkqMAcJpXYrByUlKhKKVJOSQmVVMkpV2w5YZVEK5T1IjJ1ORas0KFgUo5i6sJCgigCJAgQPACQIBZ7AHvO+c+L7l3MHiAGwAKzeOb3qZqanqe7Z58HHP766aef6TF3R0REwpVqdAVEROTiUtCLiAROQS8iEjgFvYhI4BT0IiKBSze6Aov19fX55s2bG10NEZHLyu7du0+4e/9y6+oKejPbBnwBiIAvu/vnF63/I+DXk5d5YK27dyfr7gT+fbLuP7n7V1/rb23evJmhoaF6qiUiIgkze/FM684a9GYWAQ8A7wOOALvMbIe775vbxt3/bc32HwNuSpZ7gc8Cg4ADu5N9x86zLSIico7qGaO/GTjo7ofcvQg8DNz+GtvfAfx5svx+YKe7jybhvhPYdiEVFhGRc1NP0G8EDte8PpKULWFmVwJbgMfPZV8zu9vMhsxsaHh4uJ56i4hInVZ61s124FvuXjmXndz9QXcfdPfB/v5lryWIiMh5qifojwKbal4PJGXL2c7pYZtz3VdERC6CeoJ+F7DVzLaYWZY4zHcs3sjM3gD0AD+qKX4UuNXMesysB7g1KRMRkUvkrLNu3L1sZvcQB3QEPOTue83sfmDI3edCfzvwsNfcDtPdR83sc8QHC4D73X10ZZsgIiKvxVbbbYoHBwf9fObRTxbKPPiDQ7z3DWu5cVP3RaiZiMjqZWa73X1wuXXB3AKhWK7yJ48dYM9LmqIvIlIrmKDPpeOmFMrVBtdERGR1CS7oiwp6EZEFggn6dJQiSpl69CIiiwQT9BD36gvlc/qulohI8AIMevXoRURqBRb0EYWSgl5EpFZQQZ/V0I2IyBJBBb2GbkRElgor6DMKehGRxYIK+nQqRbm6um7pICLSaIEFvVGuqEcvIlIrrKCPTD16EZFFwgr6VIqKgl5EZIGggj7S0I2IyBJBBX1GQzciIksEFfRRyjR0IyKySFBBn06lKGnoRkRkgbCCPlKPXkRksaCCPkppjF5EZLGggj7+wpSCXkSkVlhBH+kWCCIii4UV9CmjUtXFWBGRWkEFfaShGxGRJYIK+oyGbkRElggq6PWFKRGRpYIK+nTKKGmMXkRkgcCCPoU7VNWrFxGZF1bQRwagcXoRkRpBBX2Umgt6Dd+IiMwJKujTKfXoRUQWCzLoK5pLLyIyL6igj6K4OZp5IyJyWlBBP9+j19CNiMi8uoLezLaZ2X4zO2hm955hm4+Y2T4z22tmX6spr5jZnuSxY6Uqvpz5MXoN3YiIzEufbQMzi4AHgPcBR4BdZrbD3ffVbLMVuA+4xd3HzGxtzVvMuPuNK1zvZWl6pYjIUvX06G8GDrr7IXcvAg8Dty/a5veAB9x9DMDdj69sNesTpeLm6A6WIiKn1RP0G4HDNa+PJGW1rgGuMbMnzOzHZratZl2LmQ0l5R9c7g+Y2d3JNkPDw8Pn1IBaGU2vFBFZ4qxDN+fwPluB9wADwA/M7AZ3HweudPejZnYV8LiZ/dLdn6vd2d0fBB4EGBwcPO+UjjRGLyKyRD09+qPApprXA0lZrSPADncvufvzwLPEwY+7H02eDwF/C9x0gXU+I43Ri4gsVU/Q7wK2mtkWM8sC24HFs2f+krg3j5n1EQ/lHDKzHjPL1ZTfAuzjIklrjF5EZImzDt24e9nM7gEeBSLgIXffa2b3A0PuviNZd6uZ7QMqwKfcfcTM3gV8ycyqxAeVz9fO1lnxxmjoRkRkibrG6N39EeCRRWWfqVl24JPJo3abHwI3XHg16xPpYqyIyBJhfTN27hYIFQ3diIjMCSro53r0VVePXkRkTlBBrzF6EZGlggr6lKlHLyKyWFBBr3n0IiJLBRX0cz163aZYROS0oIJe96MXEVkqqKCPFPQiIkso6EVEAhdU0M8P3WjWjYjIvKCCPqUevYjIEkEFvS7GiogsFVTQq0cvIrJUUEGvHr2IyFJBBf3cF6b0zVgRkdOCCvq5Hn1VQS8iMi+ooNcPj4iILBVU0JsZKdPdK0VEagUV9BD36tWjFxE5Lcig1xi9iMhp4QW9qUcvIlIrvKBPmebRi4jUUNCLiAQuwKBP6e6VIiI1Agx6qFQU9CIic4IL+rR69CIiCwQX9KmUbmomIlIruKBPp1IKehGRGsEFfcrUoxcRqRVc0KdTKcrVaqOrISKyagQX9KmUUVHOi4jMCy7o0ymjoh69iMi84II+lTI0jV5E5LTggl49ehGRheoKejPbZmb7zeygmd17hm0+Ymb7zGyvmX2tpvxOMzuQPO5cqYqfie51IyKyUPpsG5hZBDwAvA84Auwysx3uvq9mm63AfcAt7j5mZmuT8l7gs8Ag4MDuZN+xlW9KLL5NsXr0IiJz6unR3wwcdPdD7l4EHgZuX7TN7wEPzAW4ux9Pyt8P7HT30WTdTmDbylR9eelIPXoRkVr1BP1G4HDN6yNJWa1rgGvM7Akz+7GZbTuHfTGzu81syMyGhoeH66/9MlKmoBcRqbVSF2PTwFbgPcAdwJ+aWXe9O7v7g+4+6O6D/f39F1aRlOmmZiIiNeoJ+qPApprXA0lZrSPADncvufvzwLPEwV/PvisqlTLKml8pIjKvnqDfBWw1sy1mlgW2AzsWbfOXxL15zKyPeCjnEPAocKuZ9ZhZD3BrUnbRpFNGVT16EZF5Z5114+5lM7uHOKAj4CF332tm9wND7r6D04G+D6gAn3L3EQAz+xzxwQLgfncfvRgNmZNK6cfBRURqnTXoAdz9EeCRRWWfqVl24JPJY/G+DwEPXVg165fWPHoRkQWC+2ZsSzpitlRpdDVERFaN4IK+NRsxXVTQi4jMCTLo1aMXETktuKDPZyJKFaekm9KLiAABBn1rNgLQ8I2ISCLYoNfwjYhILLigz6tHLyKyQHBB35qJvxowXSw3uCYiIqtDeEGvoRsRkQWCC3oN3YiILBRc0LdmFPQiIrXCC3oN3YiILBBc0GvoRkRkofCCPpl1M6OgFxEBAgz6lmzcpBkN3YiIAAEGfTZKEaVM8+hFRBLBBb2Z0ZqJmCnqpmYiIhBg0EM882ampB69iAgEGvR5/fiIiMi8IIM+HrpR0IuIQKhBn40060ZEJBFk0GvoRkTktCCDXkM3IiKnhRn02bSGbkREEkEGfT4T6QtTIiKJIIO+NauhGxGROeEGvYZuRESAQIM+n4koVZxSRbdBEBEJMujnfnxEvXoRkdCDXuP0IiJhBn1eQS8iMi/IoNcPhIuInBZm0GeTnxPUrYpFRMIM+tNDN5p1IyJSV9Cb2TYz229mB83s3mXW32Vmw2a2J3n8bs26Sk35jpWs/Jm0JT36idnSpfhzIiKrWvpsG5hZBDwAvA84Auwysx3uvm/Rpl9393uWeYsZd7/xwqtav772LAAnpoqX8s+KiKxK9fTobwYOuvshdy8CDwO3X9xqXZjetixmcGKi0OiqiIg0XD1BvxE4XPP6SFK22IfM7Ekz+5aZbaopbzGzITP7sZl9cLk/YGZ3J9sMDQ8P11/7M0hHKbpbM4xMKehFRFbqYuxfAZvd/c3ATuCrNeuudPdB4B8Bf2xmr1+8s7s/6O6D7j7Y39+/IhXqaMkwOatZNyIi9QT9UaC2hz6QlM1z9xF3n+s+fxl4a826o8nzIeBvgZsuoL51a8ulmSxoHr2ISD1BvwvYamZbzCwLbAcWzJ4xsw01Lz8APJ2U95hZLlnuA24BFl/EvSjacxFTBfXoRUTOOuvG3ctmdg/wKBABD7n7XjO7Hxhy9x3Ax83sA0AZGAXuSna/DviSmVWJDyqfX2a2zkXRlkszqlk3IiJnD3oAd38EeGRR2Wdqlu8D7ltmvx8CN1xgHc9LWy7NSyPTjfjTIiKrSpDfjAXobs0wOq0evYhIsEE/0JNnfLqkb8eKSNMLNug39bYCcGRspsE1ERFprHCDvicPwOFRjdOLSHMLN+h746BXj15Eml2wQd+TzxClTFMsRaTpBRv0ZkZXa4bxGQW9iDS3YIMe4imWY9OadSMizS3ooO/KZzipoBeRJhd00Pfksxq6EZGmF3TQd7dmGFePXkSaXNBB35VX0IuIBB303a1ZJgtlCmXdl15EmlfQQT93GwR9O1ZEmlnQQb91bQcAB16dbHBNREQaJ+igf/3aNgAOHFfQi0jzCjro89k0Az2tHFTQi0gTCzroAa5e264evYg0teCDfuvadp4bnqRS9UZXRUSkIZog6DsolqscGdPMGxFpTsEH/UAyxfKo7ksvIk0q+KBf39kCwLFTsw2uiYhIY4Qf9F1x0L9yUkEvIs0p+KDPZ9Ns6GrRFEsRaVrBBz3A1nUdHDg+0ehqiIg0RHME/dp2Dh6fpKopliLShJoi6K9Z185sqcpLurmZiDShpgj6q5Obm33yG3saXBMRkUuvKYL+pk3dvPGKTn720jiPP/Nqo6sjInJJNUXQp1LGV+56GwDf/tnRBtdGROTSaoqgB1jb2cKH3zrAX//yFV45qW/JikjzaJqgB/gXf+8qqg5feeKFRldFROSSaaqgv3ptBxu7W/nqD19gtqTfkRWR5lBX0JvZNjPbb2YHzezeZdbfZWbDZrYnefxuzbo7zexA8rhzJSt/Pj77D66nUK7yo0Mjja6KiMglcdagN7MIeAD4TeB64A4zu36ZTb/u7jcmjy8n+/YCnwXeDtwMfNbMelas9ufh3df0055L82dPvKB71ItIU6inR38zcNDdD7l7EXgYuL3O938/sNPdR919DNgJbDu/qq6MlkzEx957Nf/32WHu+NMfN7IqIiKXRD1BvxE4XPP6SFK22IfM7Ekz+5aZbTrHfS+pj96yhWvXdfDT50f5P08da3R1REQuqpW6GPtXwGZ3fzNxr/2r57Kzmd1tZkNmNjQ8PLxCVTqzbDrFd+65hTdt7OS+v3iS4YnCRf+bIiKNUk/QHwU21bweSMrmufuIu8+l5ZeBt9a7b7L/g+4+6O6D/f399db9grRkIv7oIzcyVajwtv/8N/yTL/+E7+zRl6lEJDz1BP0uYKuZbTGzLLAd2FG7gZltqHn5AeDpZPlR4FYz60kuwt6alK0KW9d18ParegH42UtjfOLhPXzqm7/QRVoRCUr6bBu4e9nM7iEO6Ah4yN33mtn9wJC77wA+bmYfAMrAKHBXsu+omX2O+GABcL+7j16Edpy3z/zW9Txx8AS33bCBD33xh3xz9xGmimU+fdt1DPTkG109EZELZu6rq/c6ODjoQ0NDDfv7/2HHXv7shy/QkknxudvfxD8c3HT2nUREGszMdrv74LLrFPQLuTs/em6EP/zefn720jhRyvj0bdfxzqvWcN2GDsysYXUTETkTBf15KJarfOGxZ3ng+8/Nl71hfQcP/tNBXrdGQzoisroo6C/AqdkS3959hF0vjPJ3B05QddjS18ZATyv/+tev5k0buxpdRRERBf1KeXFkiv/++EGGJws8eeQkhVKFT//963jX6/tozUSs72ppdBVFpEkp6C+CYydnuesrP+WZYxPzZb+yqZtsZGzpa2NdZwtrO3KkoxTXru/gpk3dGt8XkYvmtYL+rNMrZXnru1r43x//NZ44eILnT0zx/IkpHt17jO58lu8++QrTxYW3QX73Nf184je28tYrG3pPNxFpQurRXyTTxTIvj88wMVvmB8+e4AuPPUvVoa89x2/fdAW/887NbOrVRV0RWRkaulkFTk6X+MPv7eeFkSl+9NwI5apzzbp23rC+k+1v28S7ru5rdBVF5DKmoZtVoCuf4XMffBMQX9Tdsedlfn54nB8cGGbHL17m2nUdvOOqXjb15nnjFV1cf0UnnS1pjeuLyAVT0DfAlWva+NhvbAWgUK7wtZ+8xGNPH+cbQ0eYqfmJw3TK6G3LsqY9R197lvZcmp62LH1tWTZ0t7K+q4XIjI09rby+v71RzRGRVU5B32C5dMRHb9nCR2/ZQrlSZXiywI8PjTA8UWB8usTIZJGRqQLDk0VeHp9hfLrE6HSRxSNuN2zs4te29vGW1/Vww0AXXa0ZWjJRYxolIquKgn4VSUcpNnS18ts3DbzmduVKlQPHJ5kulilVnP93YJi/O3CCB39wiHLNnTc3r8lz/RWdXLe+k409rQz05LlyTZ6+9hxRSkNCIs1CF2MDMlOs8OSRcZ45NsH4dIlnjp1i3yuneHFkesm2123o5PX9bfTks3TnM3S1Zshn06zvynHdhk7Wd7bo+oDIZUQXY5tEazbi7Vet4e1XrVlQPlUoc3hsmmMnZzk0PMWrE7Pse/kUTx09yfhMiVMzJRbfgn+gp5XX9ea5oruVa9a1092apaMlzVs399DXliOlMwKRy4Z69EK16pyaLXF8osDoVJGnXznFrhdGOXZylsNjM0t+arH2IvHmNXk2dLXyxis6+ZVN3XS0pOlv14FA5FLTPHq5IGNTRSYL8RfA9r58ihOTBUYmixyfmOXF0WleGZ9dMFuoI5fm2vUdXL22nXWdLWxNvi9QrlZJp4yUGZkoRWs2Yk1bVkNEIitAQzdyQXrasvS0ZdnUm18yLARQqToHj0/y5JFxZksV9r86wbOvTrJz36uMTBVf871bMxFXrsmzpa+NlkxEPhvRl0wn7WvP0deRo689x5r2LB05fa9A5Hwo6OWCRSnj2vUdXLu+Y8m6YrnKM8dOcfD4JLl0RMWdSrVKueLJtYMZnj8xxf5jExTKVaaLZcamS8v+nWw6RX8S+rUHg7nvGfS35+htz9KWTZPLpOhs0RRTEVDQy0WWTad480A3bx7ornufUqXK2FSR4ckCJyaLjEwWOJEszz0fOznLU0dPMjJVfM0fc+9sSbOmPceatiy9bVl68vHZSU8+Q09blt58lp62TFyez9LVmtH1BQmOgl5WnUyUYm1nC2s7z35//2rVOTlT4sRkgeHJAmNTJaaKZQqlCidn4gvMI1NFRieLvDgyzZ7D44xNFylVlj84pAx623L0d8RnCW3ZNK3ZiHLV44NDPjlg1Bwk5g4gOnuQ1UpBL5e1VMrmryFsXbd06Gg57s5UscLYVJGx6SKjyfPYVInRqeSbyBPx2cPxUwWmimXSKWN8psT4GYaVAPLZiJ58PA01n43IZ9O0ZCJasxH55LklE9Gei+jKZ+lsSdOaiehszbCxu5WOlnj7XDqlaxGyohT00nTMjPZcmvZc+pxvFV2uVDk5U0oOEKX5g8ToVJGxqSKj00UmZsvMFCvMlCqMTBWZLVWYKVaYLpaZLVUpVqpnqR/kMxFtuTQdLWl62+JrEb1tWda0ZWnNpmnJpGjNRPMHkvZcmrZcmvZcvJ/OMKSWgl7kHKSjVDzm35477/colquMT8dTVqeLFcanSxwdn2aqUGG2XGG2WGG6WGFitsxEIb7f0bOvTjA6VWR8prTkPkdn0paNTl+cTqfIpSNymdT8cjY9t5wil5xJLFmXSfar2T8bLSzPRCmy6ZTutrqKKehFLrFsOrkGcR77VqseHwxK1fhMITlbmCqUmSqWmSxUmJwtMzZdZGSyyOhUgZlShUK5SqFUZapQZnSqSqFcpViuUiifXjdbrtR9EFlOLh1/NyKbBH92uQNKUhal4u9SdLSk6WzN0NmSprMlQ0dLmo7553hdR0uaXFpnJxdCQS9yGUmljHw2TT678u/t7pSrngR/peZgsPCAML9crlAoVSlVqsyW4juvzpYqFOf2q5zev1iOz1BGkv0qVadUib+RPTFbPmvdopTND1XVDlvNHVzasmnyueQ5e3pIqzUTP+bOROYOQPlsmrZk+1xSNndmkk5ZcGcmCnoRAeJrF5ko7mm35y5dNFSqzuRseT70J+aeCyVOzcSv4zOXanx2kpzJzCYHo4nZMq+emmWqEF8HmSrGB5vzZRZ/ka89l6a9JU1HLr5IHqWMKGXk0vFBZH7YKjJymYiu5OyjJTm45JMDTUvNASefjWhPLsJfyoOJgl5EGipKGV35DF35zIq959wQ19xF8dlSlXK1Sqkcl08XK0wXykwWyvNnLqXkDKRYqTJTrDBZKDNRKDM5W2YmOVMpV50T5eL8mUuhPHdGEx906pWy+LcoHCeXPn2WcsNAN//tjptW7N9hjoJeRIJzeojr0kXcbCkenppNzjbmrp/M1LyeLMTXUyZnyxTK8f2hiuV46GumVGGgp/Wi1E1BLyKyAlqS6warUarRFRARkYtLQS8iEjgFvYhI4BT0IiKBU9CLiAROQS8iEjgFvYhI4BT0IiKBM7+Q29VdBGY2DLx4AW/RB5xYoeqsVs3QRlA7Q9IMbYTGtvNKd+9fbsWqC/oLZWZD7j7Y6HpcTM3QRlA7Q9IMbYTV204N3YiIBE5BLyISuBCD/sFGV+ASaIY2gtoZkmZoI6zSdgY3Ri8iIguF2KMXEZEaCnoRkcAFE/Rmts3M9pvZQTO7t9H1OVdm9pCZHTezp2rKes1sp5kdSJ57knIzsz9J2vqkmb2lZp87k+0PmNmdjWjLmZjZJjP7vpntM7O9ZvaJpDy0draY2U/N7BdJO/9jUr7FzH6StOfrZpZNynPJ64PJ+s0173VfUr7fzN7fmBadmZlFZvZzM/tu8jrENr5gZr80sz1mNpSUXV6fWXe/7B9ABDwHXAVkgV8A1ze6XufYhncDbwGeqin7L8C9yfK9wB8ky7cBfw0Y8A7gJ0l5L3Aoee5Jlnsa3baa9mwA3pIsdwDPAtcH2E4D2pPlDPCTpP7fALYn5V8E/mWy/K+ALybL24GvJ8vXJ5/lHLAl+YxHjW7forZ+Evga8N3kdYhtfAHoW1R2WX1mG/6PuEL/Id4JPFrz+j7gvkbX6zzasXlR0O8HNiTLG4D9yfKXgDsWbwfcAXyppnzBdqvtAXwHeF/I7QTywM+AtxN/YzKdlM9/ZoFHgXcmy+lkO1v8Oa7dbjU8gAHgMeC9wHeTOgfVxqROywX9ZfWZDWXoZiNwuOb1kaTscrfO3V9Jlo8B65LlM7X3svl3SE7dbyLu7QbXzmRIYw9wHNhJ3FMdd/dyskltnefbk6w/Caxh9bfzj4F/B1ST12sIr40ADnzPzHab2d1J2WX1mdWPg18m3N3NLIi5sGbWDnwb+DfufsrM5teF0k53rwA3mlk38L+ANzS4SivKzH4LOO7uu83sPY2uz0X2q+5+1MzWAjvN7JnalZfDZzaUHv1RYFPN64Gk7HL3qpltAEiejyflZ2rvqv93MLMMccj/T3f/i6Q4uHbOcfdx4PvEwxjdZjbXuaqt83x7kvVdwAiru523AB8wsxeAh4mHb75AWG0EwN2PJs/HiQ/aN3OZfWZDCfpdwNbkin+W+GLPjgbXaSXsAOauzt9JPKY9V/47yRX+dwAnk9PIR4FbzawnmQVwa1K2Kljcdf8fwNPu/l9rVoXWzv6kJ4+ZtRJfh3iaOPA/nGy2uJ1z7f8w8LjHA7k7gO3JjJUtwFbgp5emFa/N3e9z9wF330z8/9vj7v6PCaiNAGbWZmYdc8vEn7WnuNw+s42+0LGCF0xuI57F8Rzw+42uz3nU/8+BV4AS8fjdPycew3wMOAD8DdCbbGvAA0lbfwkM1rzPPwMOJo+PNrpdi9r4q8TjnU8Ce5LHbQG2883Az5N2PgV8Jim/ijjEDgLfBHJJeUvy+mCy/qqa9/r9pP37gd9sdNvO0N73cHrWTVBtTNrzi+Sxdy5bLrfPrG6BICISuFCGbkRE5AwU9CIigVPQi4gETkEvIhI4Bb2ISOAU9CIigVPQi4gE7v8Dfksrgekkv7UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.losses['batch_id'], history.losses['batch_binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载已有参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./trained_data/model/PNN/alimama/0_0.632_0.6647_0.486_0.0407.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test LogLoss 0.6647\n",
      "test AUC 0.632\n",
      "test RMSE 0.486\n",
      "test RIG 0.0407\n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "auc_value = round(roc_auc_score(test[target].values, pred_ans), 4)\n",
    "logloss_value = round(log_loss(test[target].values, pred_ans), 4)\n",
    "rmse_value = round(rmse(test[target].values, pred_ans), 4)\n",
    "rig_value = round(rig(test[target].values, pred_ans)[0], 4)\n",
    "print(\"test LogLoss\", logloss_value) \n",
    "print(\"test AUC\", auc_value) \n",
    "print(\"test RMSE\", rmse_value)\n",
    "print(\"test RIG\", rig_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试专用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = build_input_features(dnn_feature_columns)\n",
    "untrainable_features = build_input_features(untrainable_features_columns)\n",
    "trainable_features = build_input_features(trainable_features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "uid_features = OrderedDict()\n",
    "uid_features['userId'] = features['userId']\n",
    "uid_feature_columns = [x for x in dnn_feature_columns if x.name == 'userId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('userId', <tf.Tensor 'userId_2:0' shape=(?, 1) dtype=int32>)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8149242401123047\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y_true = np.array([[0., 1.], [0., 0.]])\n",
    "y_pred = np.array([[0.6, 0.4], [0.4, 0.6]])\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "with tf.Session() as t:\n",
    "    print(t.run(bce(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "def cross_entropy(y, a):\n",
    "    return tf.reduce_mean((-y*np.log(a)-(1-y)*np.log(1-a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814924454847114\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as t:\n",
    "    print(t.run(cross_entropy(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as t:\n",
    "    print(t.run(cross_entropy(y_pred, y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.focal_loss.<locals>.focal_loss_fixed(y_true, y_pred)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focal_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred, gamma=0., alpha=0.25):\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return -K.mean(K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.mean(K.pow( pt_0, gamma) * K.log(1. - pt_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814924454847114\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as t:\n",
    "    print(t.run(focal_loss(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%pip3` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys \n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import chain\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from deepctr.layers import combined_dnn_input, concat_func, add_func, FM, DNN_UDG, rig, rmse, CustomCallback\n",
    "from deepctr.models import DeepFM, DeepFM_UDG, PNN, PNN_UDG, WDL, WDL_UDG\n",
    "from deepctr.inputs import create_embedding_dict, embedding_lookup, mergeDict\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, VarLenSparseFeat, get_feature_names, build_input_features, get_linear_logit,input_from_feature_columns\n",
    "from deepctr.models import DIN, DIEN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat,get_feature_names\n",
    "\n",
    "\n",
    "\n",
    "def get_xy_fd(use_neg=False, hash_flag=False):\n",
    "    feature_columns = [SparseFeat('user', 3, embedding_dim=10, use_hash=hash_flag),\n",
    "                       SparseFeat('gender', 2, embedding_dim=4, use_hash=hash_flag),\n",
    "                       SparseFeat('item_id', 3 + 1, embedding_dim=8, use_hash=hash_flag),\n",
    "                       SparseFeat('cate_id', 2 + 1, embedding_dim=4, use_hash=hash_flag),\n",
    "                       DenseFeat('pay_score', 1)]\n",
    "\n",
    "    feature_columns += [\n",
    "        VarLenSparseFeat(SparseFeat('hist_item_id', vocabulary_size=3 + 1, embedding_dim=8, embedding_name='item_id'),\n",
    "                         maxlen=4, length_name=\"seq_length\"),\n",
    "        VarLenSparseFeat(SparseFeat('hist_cate_id', 2 + 1, embedding_dim=4, embedding_name='cate_id'), maxlen=4,\n",
    "                         length_name=\"seq_length\")]\n",
    "\n",
    "    behavior_feature_list = [\"item_id\", \"cate_id\"]\n",
    "    uid = np.array([0, 1, 2])\n",
    "    ugender = np.array([0, 1, 0])\n",
    "    iid = np.array([1, 2, 3])  # 0 is mask value\n",
    "    cate_id = np.array([1, 2, 2])  # 0 is mask value\n",
    "    score = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "    hist_iid = np.array([[1, 2, 3, 0], [1, 2, 3, 0], [1, 2, 0, 0]])\n",
    "    hist_cate_id = np.array([[1, 2, 2, 0], [1, 2, 2, 0], [1, 2, 0, 0]])\n",
    "\n",
    "    behavior_length = np.array([3, 3, 2])\n",
    "\n",
    "    feature_dict = {'user': uid, 'gender': ugender, 'item_id': iid, 'cate_id': cate_id,\n",
    "                    'hist_item_id': hist_iid, 'hist_cate_id': hist_cate_id,\n",
    "                    'pay_score': score, \"seq_length\": behavior_length }\n",
    "\n",
    "    if use_neg:\n",
    "        feature_dict['neg_hist_item_id'] = np.array([[1, 2, 3, 0], [1, 2, 3, 0], [1, 2, 0, 0]])\n",
    "        feature_dict['neg_hist_cate_id'] = np.array([[1, 2, 2, 0], [1, 2, 2, 0], [1, 2, 0, 0]])\n",
    "        feature_columns += [\n",
    "            VarLenSparseFeat(SparseFeat('neg_hist_item_id', vocabulary_size=3 + 1, embedding_dim=8, embedding_name='item_id'),\n",
    "                             maxlen=4, length_name=\"seq_length\"),\n",
    "            VarLenSparseFeat(SparseFeat('neg_hist_cate_id', 2 + 1, embedding_dim=4, embedding_name='cate_id'),\n",
    "                             maxlen=4, length_name=\"seq_length\")]\n",
    "\n",
    "    x = {name: feature_dict[name] for name in get_feature_names(feature_columns)}\n",
    "    y = np.array([1, 0, 1])\n",
    "    return x, y, feature_columns, behavior_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:56:35.220883 140540279412544 deprecation.py:323] From ../deepctr/layers/sequence.py:724: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0812 16:56:35.468105 140540279412544 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0812 16:56:36.258097 140540279412544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0812 16:56:38.612336 140540279412544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0812 16:56:38.624126 140540279412544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0812 16:56:38.641061 140540279412544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0812 16:56:38.820410 140540279412544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:255: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0812 16:56:38.864310 140540279412544 deprecation.py:323] From ../deepctr/models/dien.py:66: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate/concat:0\", shape=(?, 4, 12), dtype=float32)\n",
      "Tensor(\"concatenate_3/concat:0\", shape=(?, 4, 12), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:56:40.200302 140540279412544 deprecation.py:323] From ../deepctr/models/dien.py:73: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0812 16:56:40.916222 140540279412544 deprecation_wrapper.py:119] From ../deepctr/models/dien.py:44: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0812 16:56:42.041317 140540279412544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:253: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "W0812 16:56:42.736078 140540279412544 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0812 16:56:42.776351 140540279412544 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0812 16:56:42.813614 140540279412544 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0812 16:56:44.253526 140540279412544 deprecation_wrapper.py:119] From ../deepctr/models/dien.py:263: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "W0812 16:56:44.254978 140540279412544 deprecation_wrapper.py:119] From ../deepctr/models/dien.py:263: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x, y, feature_columns, behavior_feature_list = get_xy_fd(use_neg=True)\n",
    "model = DIEN(feature_columns, behavior_feature_list,\n",
    "             dnn_hidden_units=[4, 4, 4], dnn_dropout=0.6, gru_type=\"AUGRU\", use_negsampling=True)\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy',\n",
    "              metrics=['binary_crossentropy'])\n",
    "#history = model.fit(x, y, verbose=1, epochs=10, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 7ms/sample - loss: 1.6662 - binary_crossentropy: 0.6911\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 7ms/sample - loss: 1.6665 - binary_crossentropy: 0.6913\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 6ms/sample - loss: 1.6681 - binary_crossentropy: 0.6929\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 6ms/sample - loss: 1.6654 - binary_crossentropy: 0.6902\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 7ms/sample - loss: 1.6660 - binary_crossentropy: 0.6908\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 7ms/sample - loss: 1.6658 - binary_crossentropy: 0.6907\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 7ms/sample - loss: 1.6667 - binary_crossentropy: 0.6916\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 6ms/sample - loss: 1.6655 - binary_crossentropy: 0.6903\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 7ms/sample - loss: 1.6663 - binary_crossentropy: 0.6911\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 6ms/sample - loss: 1.6652 - binary_crossentropy: 0.6900\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, verbose=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
